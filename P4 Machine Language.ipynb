{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fIjjuZqVhcdL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ws74z_xT2T8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ErnC2PR5N2Yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7bf1caa9-2e8a-4b6f-907b-66ee41ca138e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Go.\tVe.\n",
            "Go.\tVete.\n",
            "Go.\tVaya.\n",
            "Go.\tVáyase.\n",
            "Hi.\tHola.\n",
            "Run!\t¡Corre!\n",
            "Run.\tCorred.\n",
            "Who?\t¿Quién?\n",
            "Fire!\t¡Fuego!\n",
            "Fire!\t¡Incendio!\n",
            "Fire!\t¡Disparad!\n",
            "Help!\t¡Ayuda!\n",
            "Help!\t¡Socorro! ¡Auxilio!\n",
            "Help!\t¡Auxilio!\n",
            "Jump!\t¡Salta!\n",
            "Jump.\tSalte.\n",
            "Stop!\t¡Parad!\n",
            "Stop!\t¡Para!\n",
            "Stop!\t¡Pare!\n",
            "Wait!\t¡Espera!\n",
            "Wait.\tEsperen.\n",
            "Go on.\tContinúa.\n",
            "Go on.\tContinúe.\n",
            "Hello!\tHola.\n",
            "I ran.\tCorrí.\n",
            "I ran.\tCorría.\n",
            "I try.\tLo intento.\n",
            "I won!\t¡He ganado!\n",
            "Oh no!\t¡Oh, no!\n",
            "Relax.\tTomátelo con soda.\n",
            "Smile.\tSonríe.\n",
            "Attack!\t¡Al ataque!\n",
            "Attack!\t¡Atacad!\n",
            "Ge\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=url,\n",
        "    extract=False,\n",
        "    cache_dir=\"/content\",\n",
        "    cache_subdir=\"\"\n",
        ")\n",
        "\n",
        "extract_path = Path(\"/content/spa-eng-data\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "text_path = extract_path / \"spa-eng\" / \"spa.txt\"\n",
        "text = text_path.read_text(encoding='utf-8')\n",
        "\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs) # separates the pairs into 2 lists"
      ],
      "metadata": {
        "id": "vowmrQYGPcfu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english = list(sentences_en)"
      ],
      "metadata": {
        "id": "Q6e6h_qzPix1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish = ['<bos> ' + sentence + ' <eos>' for sentence in sentences_es]"
      ],
      "metadata": {
        "id": "Wz1bj49VPml0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentences):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(sentences)\n",
        "  sequence = tokenizer.texts_to_sequences(sentences)\n",
        "  return tokenizer, sequence"
      ],
      "metadata": {
        "id": "hWfqa48ngrAs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_tokenizer, english_sequence = tokenizer(english)"
      ],
      "metadata": {
        "id": "Flb6tU4qhgfZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_tokenizer, spanish_sequence = tokenizer(spanish)"
      ],
      "metadata": {
        "id": "l4IcKmy5hpzL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_maxlen = max(len(i) for i in english_sequence)"
      ],
      "metadata": {
        "id": "c3dmIw2JoHjn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_maxlen = max(len(i) for i in spanish_sequence)"
      ],
      "metadata": {
        "id": "1Wcv64V_oHbC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vocab_size = len(english_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "uiMqnRWqiPGv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_vocab_size = len(spanish_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "JLxojdeoiQ86"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_padding = pad_sequences(english_sequence, maxlen = english_maxlen , padding = 'post')"
      ],
      "metadata": {
        "id": "wbfUEP4-izXA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_padding = pad_sequences(spanish_sequence, maxlen = spanish_maxlen, padding = 'post')"
      ],
      "metadata": {
        "id": "o4j5K0MWi9t-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKzrs0xoyFtI",
        "outputId": "5605f664-bf9f-4a75-cd60-cd81d86023dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26040"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ_-Igm1yFqm",
        "outputId": "9117566e-c28e-4949-fdf8-514bd3f21198"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13525"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0G88j28MjYgC",
        "outputId": "05abdc45-a10b-4250-f895-ee05f6443c4c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   75,   67, ...,    0,    0,    0],\n",
              "       [   1,   13, 1019, ...,    0,    0,    0],\n",
              "       [   1,  164,    4, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1, 4896,  133, ...,    0,    0,    0],\n",
              "       [   1,    7,    6, ...,    0,    0,    0],\n",
              "       [   1,   52,  331, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = np.zeros_like(spanish_padding)\n",
        "decoder_target[:, :-1] = spanish_padding[:, 1:]"
      ],
      "metadata": {
        "id": "dSjHKV8Ljnxq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZN6yNujm5GG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# --- Encoder ---\n",
        "encoder_inputs = Input(shape=(english_maxlen,))\n",
        "encoder_embedding_layer = Embedding(\n",
        "    input_dim=english_vocab_size,\n",
        "    output_dim=128,\n",
        "    mask_zero=True\n",
        ")\n",
        "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "# LSTM with dropout\n",
        "encoder_lstm_layer = LSTM(\n",
        "    512,\n",
        "    return_state=True,\n",
        "\n",
        ")\n",
        "encoder_output, hidden_state, cell_state = encoder_lstm_layer(encoder_embedding)\n",
        "encoder_states = [hidden_state, cell_state]\n",
        "\n",
        "# --- Decoder ---\n",
        "decoder_inputs = Input(shape=(spanish_maxlen,))\n",
        "decoder_embedding_layer = Embedding(\n",
        "    input_dim=spanish_vocab_size,\n",
        "    output_dim=128,\n",
        "    mask_zero=True\n",
        ")\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(\n",
        "    512,\n",
        "    return_sequences=True,\n",
        "    return_state=True,\n",
        ")\n",
        "decoder_output, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Dropout before dense output\n",
        "decoder_output = Dropout(0.3)(decoder_output)\n",
        "\n",
        "# TimeDistributed Dense for sequence output\n",
        "decoder_dense = TimeDistributed(Dense(spanish_vocab_size, activation='softmax'))\n",
        "output = decoder_dense(decoder_output)"
      ],
      "metadata": {
        "id": "aYeJSswknI3w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], output)"
      ],
      "metadata": {
        "id": "UhZO1bjwnQ3L"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "5la-SJvlp0BT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilbJ63B7tXk_",
        "outputId": "e3a11c87-aa82-4c3b-e274-415fe62de1b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118964, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder_target = np.expand_dims(decoder_target, axis =-1)\n",
        "decoder_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkkVOdBcst75",
        "outputId": "e40549cb-1775-4687-d762-4c326b54dec3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118964, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)"
      ],
      "metadata": {
        "id": "sQU2jv781hIZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model = model.fit([english_padding, spanish_padding], decoder_target, validation_split=0.2,epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzKRA65ascC9",
        "outputId": "f177e5d5-8639-4168-a67d-1ead5461a2f9",
        "collapsed": true
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 203ms/step - accuracy: 0.1112 - loss: 4.9606 - val_accuracy: 0.0736 - val_loss: 3.3123\n",
            "Epoch 2/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 202ms/step - accuracy: 0.0767 - loss: 3.0679 - val_accuracy: 0.0872 - val_loss: 2.6426\n",
            "Epoch 3/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 203ms/step - accuracy: 0.0910 - loss: 2.3331 - val_accuracy: 0.0951 - val_loss: 2.3059\n",
            "Epoch 4/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 202ms/step - accuracy: 0.1006 - loss: 1.8543 - val_accuracy: 0.1006 - val_loss: 2.1068\n",
            "Epoch 5/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 203ms/step - accuracy: 0.1082 - loss: 1.5128 - val_accuracy: 0.1033 - val_loss: 1.9968\n",
            "Epoch 6/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 203ms/step - accuracy: 0.1142 - loss: 1.2559 - val_accuracy: 0.1050 - val_loss: 1.9459\n",
            "Epoch 7/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 202ms/step - accuracy: 0.1195 - loss: 1.0600 - val_accuracy: 0.1062 - val_loss: 1.9169\n",
            "Epoch 8/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 202ms/step - accuracy: 0.1240 - loss: 0.9126 - val_accuracy: 0.1068 - val_loss: 1.9070\n",
            "Epoch 9/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 202ms/step - accuracy: 0.1278 - loss: 0.7988 - val_accuracy: 0.1073 - val_loss: 1.9106\n",
            "Epoch 10/10\n",
            "\u001b[1m2975/2975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 202ms/step - accuracy: 0.1303 - loss: 0.7167 - val_accuracy: 0.1075 - val_loss: 1.9259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1_60-Yhsr7l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  seq = english_tokenizer.texts_to_sequences([sentence])\n",
        "  seq = pad_sequences(seq, maxlen = english_maxlen, padding = 'post')\n",
        "  seq = tf.convert_to_tensor(seq)\n",
        "\n",
        "\n",
        "  encoder_embedding = encoder_embedding_layer(seq)\n",
        "  _,state_h, state_c = encoder_lstm_layer(encoder_embedding)\n",
        "  states = [state_h, state_c]\n",
        "\n",
        "  bos_token = spanish_tokenizer.word_index.get('bos')\n",
        "  eos_token = spanish_tokenizer.word_index.get('eos')\n",
        "\n",
        "  target_seq = tf.convert_to_tensor([[bos_token]], dtype = tf.int32)\n",
        "  decoded_words = []\n",
        "\n",
        "  for i in range(spanish_maxlen):\n",
        "      decoder_embedding = decoder_embedding_layer(target_seq)\n",
        "      decoder_outputs,state_h,state_c = decoder_lstm(decoder_embedding, initial_state = states)\n",
        "      output = decoder_dense(decoder_outputs)\n",
        "\n",
        "      word_id = np.argmax(output[0, -1, :].numpy())\n",
        "\n",
        "      if word_id == eos_token:\n",
        "          break\n",
        "      word = spanish_tokenizer.index_word.get(word_id)\n",
        "\n",
        "      if word:\n",
        "        decoded_words.append(word)\n",
        "\n",
        "      target_seq = tf.convert_to_tensor([[word_id]], dtype = tf.int32)\n",
        "      states = [state_h, state_c]\n",
        "  return decoded_words"
      ],
      "metadata": {
        "id": "AiEoRMV3MD49"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I am happy'"
      ],
      "metadata": {
        "id": "IHsQ352M4_at"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_list = translate(sentence)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1f4Cj0945Cel"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_sentences = ' '.join(spanish_list)"
      ],
      "metadata": {
        "id": "LWTuy68OAidv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spanish_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fTmRl2cMIxf",
        "outputId": "e897ca95-0fc2-45d3-f97d-9c191ec4aa4f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estoy feliz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'What is your name?'"
      ],
      "metadata": {
        "id": "1rGDk9HEMIpF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_list = translate(sentence)"
      ],
      "metadata": {
        "id": "LO2V_WEMMImh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_sentences = ' '.join(spanish_list)"
      ],
      "metadata": {
        "id": "K_n1KvDVQ5Sx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spanish_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoGGDoNUU2Mh",
        "outputId": "fd87ef66-68df-4fb9-ba06-82646b26bf81"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuál es tu nombre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'This model translates english to spanish fluently'"
      ],
      "metadata": {
        "id": "iLT0TJpjU4Tt"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_list = translate(sentence)"
      ],
      "metadata": {
        "id": "7hk61TT-VkGC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_sentences = ' '.join(spanish_list)"
      ],
      "metadata": {
        "id": "TIBlgWBNVmZV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spanish_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5x2hb8uVnn7",
        "outputId": "0191c7fa-33c6-4dee-99ba-920e39494763"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "este va a estudiar inglés con fluidez\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Thank You'"
      ],
      "metadata": {
        "id": "1l9JW189Voxi"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_list = translate(sentence)"
      ],
      "metadata": {
        "id": "pIQ2jLr1V6j7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_sentences = ' '.join(spanish_list)"
      ],
      "metadata": {
        "id": "AzSxEZ7xV74w"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spanish_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24WhNPJGV9F3",
        "outputId": "b7be7478-f6db-4e33-bbb3-2d644f833f35"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gracias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppYmT9R0V-ge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}